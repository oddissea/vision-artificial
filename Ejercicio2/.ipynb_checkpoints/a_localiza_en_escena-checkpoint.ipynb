{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1976,
     "status": "ok",
     "timestamp": 1672743938723,
     "user": {
      "displayName": "FH Nasser",
      "userId": "15838958893200702219"
     },
     "user_tz": 0
    },
    "id": "oAR0NCFMdAAo",
    "outputId": "38f86313-48ff-4e3f-9b73-197bc6952e5b"
   },
   "outputs": [],
   "source": [
    "# Importa la función para la representación de las imágenes\n",
    "import sys  \n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import resources as src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1672743939996,
     "user": {
      "displayName": "FH Nasser",
      "userId": "15838958893200702219"
     },
     "user_tz": 0
    },
    "id": "YNfjBCpTdu3g"
   },
   "outputs": [],
   "source": [
    "path_box = \"../data/box.png\"\n",
    "path_box_scene = \"../data/box_in_scene.png\"\n",
    "\n",
    "\n",
    "# path_box = '../data/cruces/modelo_cruz_griega.jpg'\n",
    "# path_box_scene = '../data/cruces/cruces_mezcladas_contorno_incompleto.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8lMIvcmL-VP"
   },
   "source": [
    "Este código realiza una búsqueda de imagen utilizando el algoritmo SIFT (Scale-Invariant Feature Transform) y el algoritmo de emparejamiento de vecinos más cercanos basado en índices FLANN (Fast Library for Approximate Nearest Neighbors).\n",
    "\n",
    "La imagen de consulta es \"box.png\" y la imagen de entrenamiento es \"box_in_scene.png\". Primero, se detectan y extraen los puntos clave y sus descriptores de ambas imágenes utilizando el detector SIFT. Luego, se crea un objeto \"flann\" utilizando los parámetros de índice y búsqueda especificados. Finalmente, se utiliza el objeto \"flann\" para encontrar parejas de puntos clave coincidentes entre las dos imágenes utilizando el método \"knnMatch\".\n",
    "\n",
    "Luego, se aplica una prueba de relación de Lowe a cada par de coincidencias para filtrar las \"buenas\" coincidencias. La prueba de relación de Lowe consiste en mantener solo aquellas coincidencias cuya distancia es menor que un cierto porcentaje (0,7 en este caso) de la distancia del segundo mejor vecino más cercano. Esto se hace para eliminar las coincidencias que son menos confiables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1672743943128,
     "user": {
      "displayName": "FH Nasser",
      "userId": "15838958893200702219"
     },
     "user_tz": 0
    },
    "id": "XI_QVBEteW9p"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "box = cv.imread(path_box, 0)\n",
    "box_scene = cv.imread(path_box_scene, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1672743945537,
     "user": {
      "displayName": "FH Nasser",
      "userId": "15838958893200702219"
     },
     "user_tz": 0
    },
    "id": "2_Pq2B35hPat"
   },
   "outputs": [],
   "source": [
    "MIN_MATCH_COUNT = 10\n",
    "\n",
    "# Inicia el detector SIFT\n",
    "sift = cv.SIFT_create()\n",
    "\n",
    "# Encuentra los puntos clave y los descriptores\n",
    "kp1, des1 = sift.detectAndCompute(box,None)\n",
    "kp2, des2 = sift.detectAndCompute(box_scene,None)\n",
    "\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "# Almacena las coincidencias dentro del radio.\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se encuentran suficientes coincidencias \"buenas\" (es decir, si hay más de MIN_MATCH_COUNT coincidencias), entonces el código procede a calcular la homografía entre las dos imágenes. La homografía es una transformación que se aplica a una imagen para hacerla coincidir con otra imagen vista desde una perspectiva diferente.\n",
    "\n",
    "Para calcular la homografía, se utiliza el método \"findHomography\" de OpenCV. Esta función toma como entrada dos conjuntos de puntos, src_pts y dst_pts, que son correspondencias entre puntos clave en la imagen de consulta y la imagen de entrenamiento. También se proporciona el método de estimación RANSAC (RANdom SAmple Consensus) para eliminar las correspondencias erróneas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPLy6aLtMGAe"
   },
   "source": [
    "Una vez que se ha calculado la homografía, se aplica a la imagen de entrenamiento para dibujar un cuadrilátero alrededor de la región de la imagen de entrenamiento que coincide con la imagen de consulta. Esto se hace utilizando la función \"perspectiveTransform\" de OpenCV. Por último, se dibuja el cuadrilátero en la imagen de entrenamiento utilizando la función \"polylines\".\n",
    "\n",
    "Si no se encuentran suficientes coincidencias \"buenas\", se imprime un mensaje de error y se establece la variable \"matchesMask\" como \"None\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1672745582677,
     "user": {
      "displayName": "FH Nasser",
      "userId": "15838958893200702219"
     },
     "user_tz": 0
    },
    "id": "Q0agpjs5iXU8"
   },
   "outputs": [],
   "source": [
    "if len(good) > MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    "    h,w = box.shape\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "    dst = cv.perspectiveTransform(pts,M)\n",
    "    img2 = cv.polylines(box_scene, [np.int32(dst)], True, 3, 3, cv.LINE_AA)\n",
    "else:\n",
    "    print( \"No se encontraron suficientes coincidencias - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "    matchesMask = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTSHytivMaUW"
   },
   "source": [
    "Esta última parte del código se utiliza para dibujar las coincidencias encontradas en una imagen y mostrarla. Se crea un diccionario \"draw_params\" con los parámetros de dibujo para la función \"drawMatches\" de OpenCV. Estos parámetros incluyen el color en el que se deben dibujar las coincidencias (verde), si se deben dibujar todas las coincidencias o solo las inliers (matchesMask), y el estilo de dibujo de las líneas que unen las correspondencias (FLAGS_DRAW_RICH_KEYPOINTS).\n",
    "\n",
    "Luego se llama a la función \"drawMatches\" con las imágenes de consulta y de entrenamiento, los puntos clave y sus descriptores, y la lista de coincidencias \"buenas\" como argumentos. Esto devuelve una imagen con las coincidencias dibujadas. Por último, Se muestra la imagen en pantalla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1672745584100,
     "user": {
      "displayName": "FH Nasser",
      "userId": "15838958893200702219"
     },
     "user_tz": 0
    },
    "id": "GSS0iGnajOAg"
   },
   "outputs": [],
   "source": [
    "draw_params = dict(matchColor = (0,255,0), # Dibuja las coincidencias\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # Dibuja solo los inliers\n",
    "                   flags = 2)\n",
    "img3 = cv.drawMatches(box, kp1, box_scene, kp2, good, None, **draw_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "executionInfo": {
     "elapsed": 2845,
     "status": "ok",
     "timestamp": 1672745589336,
     "user": {
      "displayName": "FH Nasser",
      "userId": "15838958893200702219"
     },
     "user_tz": 0
    },
    "id": "bP8yz-DVIsnp",
    "outputId": "b4948282-74ee-489d-af2e-d3996074fce8"
   },
   "outputs": [],
   "source": [
    "# Muestra las imágenes \n",
    "src.mostrar_imagenes(1, 1, ['Coincidencias entre las imágenes'], [img3], 20, 14, (False, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4PPDSSCOzJL"
   },
   "source": [
    "Para calcular la posición del cuadrilátero, se calcula la media de las coordenadas x e y de los puntos de destino \"dst\". Con lo que se obtiene un punto central aproximado para el cuadrilátero en la imagen de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1672746883159,
     "user": {
      "displayName": "FH Nasser",
      "userId": "15838958893200702219"
     },
     "user_tz": 0
    },
    "id": "DhK15xA7bpiT",
    "outputId": "c77e8d16-08fc-430a-8f33-dde7a246a76b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[118.79797, 160.89099]],\n",
       "\n",
       "       [[ 89.65635, 272.0471 ]],\n",
       "\n",
       "       [[267.45065, 297.9469 ]],\n",
       "\n",
       "       [[284.19675, 175.06491]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector de coordenadas de los puntos que muestran las esquinas del cuadrilátero\n",
    "dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1672746769833,
     "user": {
      "displayName": "FH Nasser",
      "userId": "15838958893200702219"
     },
     "user_tz": 0
    },
    "id": "AeLw2jGxd2-b",
    "outputId": "ca793c26-5931-440e-c0ca-7492c430d7c4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Se estran las coordenadas de los puntos\n",
    "x = dst[:,:,0]\n",
    "y = dst[:,:,1]\n",
    "\n",
    "# Se muestran en pantalla\n",
    "plt.scatter(x, y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 476,
     "status": "ok",
     "timestamp": 1672743960236,
     "user": {
      "displayName": "FH Nasser",
      "userId": "15838958893200702219"
     },
     "user_tz": 0
    },
    "id": "HgZwnvVAO1Es",
    "outputId": "4c530e36-4a6c-407e-aa8d-71539322bd78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La posición se encuentra en el punto (190.02542114257812, 226.48748779296875)\n"
     ]
    }
   ],
   "source": [
    "x_pos = np.mean(dst[:,:,0])\n",
    "y_pos = np.mean(dst[:,:,1])\n",
    "\n",
    "print (f'La posición se encuentra en el punto ({x_pos}, {y_pos})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "421rrIPFO5dD"
   },
   "source": [
    "Para calcular la orientación del cuadrilátero, se calcula el ángulo entre dos de los lados del cuadrilátero y se le restan 90 grados para obtener el ángulo con respecto a la transformación horizontal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1672743961749,
     "user": {
      "displayName": "FH Nasser",
      "userId": "15838958893200702219"
     },
     "user_tz": 0
    },
    "id": "oUCj7LE9O-Ul",
    "outputId": "f46c534e-2822-4884-cadf-e04629e70421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El ángulo de orientación es (7.760340496041593)\n"
     ]
    }
   ],
   "source": [
    "dx = dst[2][0][0] - dst[3][0][0]\n",
    "dy = dst[2][0][1] - dst[3][0][1]\n",
    "angle = np.arctan2(dy, dx) * 180 / np.pi\n",
    "\n",
    "print (f'El ángulo de orientación es ({angle - 90})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsySnKugPCOd"
   },
   "source": [
    "Este cálculo utiliza la función \"arctan2\" de NumPy para calcular el ángulo en radianes y luego lo convierte a grados utilizando la constante pi. Lo que da el ángulo en grados entre el lado derecho e inferior del cuadrilátero en la imagen de entrenamiento. Si se necesita calcular el ángulo entre otros lados del cuadrilátero, hay que cambiar los índices de los puntos de destino \"dst\" que se utilizan para calcular dx y dy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "executionInfo": {
     "elapsed": 924,
     "status": "ok",
     "timestamp": 1672747160794,
     "user": {
      "displayName": "FH Nasser",
      "userId": "15838958893200702219"
     },
     "user_tz": 0
    },
    "id": "b-7dYAqWTMN9",
    "outputId": "6a3d8064-ec5a-4829-d9d2-34cf4b0a6e04"
   },
   "outputs": [],
   "source": [
    "# Obtener las dimensiones de la imagen\n",
    "height, width = img2.shape[:2]\n",
    "\n",
    "# Definir el ROI a extraer\n",
    "x1 = int(89.832504)\n",
    "y1 = int(160.96033)\n",
    "x2 = int(284.3881)\n",
    "y2 = int(297.9169 )\n",
    "roi = box_scene[y1:y2, x1:x2]\n",
    "\n",
    "# Mostrar el ROI extraído\n",
    "src.mostrar_imagenes(1, 1, ['ROI'], [roi], 10, 10, (True, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMjNXbfGgO1dfIvXkXQ+HgJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
